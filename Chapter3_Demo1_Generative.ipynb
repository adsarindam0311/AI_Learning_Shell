{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EU-TGXO3tE9k",
        "outputId": "350bb1da-d6fe-42ca-8731-fa5d3be1c564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (0.60.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy (from sentence-transformers)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba) (0.43.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, faiss-cpu, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-cpu-1.12.0 gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "5a1438ce29b046c88eaa1027b30ea20b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install requests tqdm faiss-cpu transformers tensorflow sentence-transformers textblob gensim numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Zx-cM6tKky",
        "outputId": "f6413bf6-5eff-4f42-bfef-8deeaeba598d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "88121KB [00:01, 85286.56KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Dataset downloaded and extracted.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Directory to store downloaded and extracted data\n",
        "DATA_DIR = Path(\"./mimic_textbooks\")\n",
        "\n",
        "# Download and extract the dataset zip file\n",
        "def download_and_extract_zip(url, extract_to=DATA_DIR):\n",
        "    # Ensure the directory exists\n",
        "    extract_to.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download the zip file\n",
        "    zip_path = extract_to / \"textbooks.zip\"\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(zip_path, \"wb\") as file:\n",
        "        for chunk in tqdm(response.iter_content(chunk_size=1024), unit='KB'):\n",
        "            if chunk:\n",
        "                file.write(chunk)\n",
        "\n",
        "    # Extract the zip file\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(\"Dataset downloaded and extracted.\")\n",
        "\n",
        "# Download and extract textbooks\n",
        "dataset_url = \"https://www.dropbox.com/scl/fi/54p9kkx5n93bffyx08eba/textbooks.zip?rlkey=2y2c5x8y0uncnddichn9cmd7n&st=m290nmkk&dl=1\"\n",
        "download_and_extract_zip(dataset_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e9bbpzvtNFX",
        "outputId": "16e3e7b9-8037-427f-e89e-48cfe5d10233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total document chunks created: 1086\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from gensim.utils import simple_preprocess\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load text files\n",
        "def load_text_files(directory):\n",
        "    texts = []\n",
        "    for file_path in Path(directory).glob(\"F*.txt\"):\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            texts.append(file.read())\n",
        "    return texts\n",
        "\n",
        "# Cleaning and preprocessing function\n",
        "def clean_and_tokenize(text):\n",
        "    # Basic regex cleaning\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = text.lower()  # Lowercase all text\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
        "\n",
        "    # Tokenize with gensim\n",
        "    tokens = simple_preprocess(text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Spell correction\n",
        "def correct_spelling(text):\n",
        "    return str(TextBlob(text).correct())\n",
        "\n",
        "# Chunk text into fixed-size chunks\n",
        "def chunk_text(text, chunk_size=200):\n",
        "    words = text.split()\n",
        "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
        "\n",
        "# Load, clean, correct, and chunk documents\n",
        "documents = load_text_files(DATA_DIR / \"textbooks/en\")\n",
        "cleaned_documents = [clean_and_tokenize(doc) for doc in documents]\n",
        "# corrected_documents = [correct_spelling(doc) for doc in cleaned_documents]\n",
        "chunked_documents = []\n",
        "for doc in cleaned_documents:\n",
        "    chunked_documents.extend(chunk_text(doc))\n",
        "\n",
        "print(f\"Total document chunks created: {len(chunked_documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Using Torch Instead of tensor to resolve the error **"
      ],
      "metadata": {
        "id": "c2Sk_7GGY1_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to generate embeddings for all chunks in a batch\n",
        "def get_embeddings_in_batch(texts, batch_size=16):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "        # Tokenize the batch of texts and move to device\n",
        "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "\n",
        "        # Generate embeddings on the GPU\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs).last_hidden_state  # [batch_size, sequence_length, hidden_size]\n",
        "            batch_embeddings = outputs.mean(dim=1)  # Mean pooling\n",
        "\n",
        "        # Move to CPU and convert to numpy\n",
        "        all_embeddings.extend(batch_embeddings.cpu().numpy())\n",
        "\n",
        "    return np.array(all_embeddings)\n",
        "\n",
        "# Generate embeddings for all document chunks in batches\n",
        "embeddings = get_embeddings_in_batch(chunked_documents, batch_size=128)\n",
        "print(f\"Generated embeddings for {len(embeddings)} document chunks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKOPfgPDZJmd",
        "outputId": "37dd0ae8-3525-4a85-a88a-2abbe416d4ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated embeddings for 1086 document chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p7qLJ9NYtUnV"
      },
      "outputs": [],
      "source": [
        "# from transformers import TFAutoModel, AutoTokenizer\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "\n",
        "# # Load the model and tokenizer\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "# model = TFAutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# # Function to generate embeddings for all chunks in a batch\n",
        "# def get_embeddings_in_batch(texts, batch_size=16):\n",
        "#     all_embeddings = []\n",
        "#     for i in range(0, len(texts), batch_size):\n",
        "#         batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "#         # Tokenize the batch of texts\n",
        "#         inputs = tokenizer(batch_texts, return_tensors=\"tf\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "#         # Generate embeddings on the GPU\n",
        "#         outputs = model(inputs).last_hidden_state  # [batch_size, sequence_length, hidden_size]\n",
        "#         batch_embeddings = tf.reduce_mean(outputs, axis=1).numpy()  # Mean pooling\n",
        "\n",
        "#         # Append batch embeddings to the list\n",
        "#         all_embeddings.extend(batch_embeddings)\n",
        "\n",
        "#     return np.array(all_embeddings)\n",
        "\n",
        "# # Generate embeddings for all document chunks in batches\n",
        "# embeddings = get_embeddings_in_batch(chunked_documents, batch_size=128)\n",
        "# print(f\"Generated embeddings for {len(embeddings)} document chunks.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gFJHoP_0tX5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c2582c-3ebd-421f-9500-860284550917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total embeddings indexed: 1086\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Define the dimension of embeddings\n",
        "dimension = 384  # Embedding size from MiniLM model\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# Convert embeddings to NumPy array for FAISS\n",
        "embedding_matrix = np.array([embedding.flatten() for embedding in embeddings]).astype('float32')\n",
        "\n",
        "# Add embeddings to FAISS index\n",
        "index.add(embedding_matrix)\n",
        "print(f\"Total embeddings indexed: {index.ntotal}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different way of deleting GPU memory**"
      ],
      "metadata": {
        "id": "JyiLiWNncdGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "# Safely delete model if it exists\n",
        "try:\n",
        "    del model\n",
        "except NameError:\n",
        "    print(\"Model was not defined or already deleted.\")\n",
        "\n",
        "# Clear PyTorch GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Run Python garbage collector\n",
        "gc.collect()\n",
        "\n",
        "# Optional: Reset CUDA device (only if you're sure it's needed)\n",
        "try:\n",
        "    from numba import cuda\n",
        "    device = cuda.get_current_device()\n",
        "    device.reset()\n",
        "except Exception as e:\n",
        "    print(f\"CUDA device reset failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kddyfqDybuZH",
        "outputId": "ce65e1bd-08e0-4f3d-f671-e68341ba3d6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was not defined or already deleted.\n",
            "CUDA device reset failed: Error at driver init: \n",
            "\n",
            "CUDA driver library cannot be found.\n",
            "If you are sure that a CUDA driver is installed,\n",
            "try setting environment variable NUMBA_CUDA_DRIVER\n",
            "with the file path of the CUDA driver shared library.\n",
            ":\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "from numba import cuda\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()  # Clear GPU memory from torch\n",
        "gc.collect()\n",
        "device = cuda.get_current_device() # Clear GPU memory from tf\n",
        "device.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "micHMz6RpLxx",
        "outputId": "1295256c-d676-40f7-ca61-88cff216f074"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-742749495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear GPU memory from torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "prxdol-LqNZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrival Method"
      ],
      "metadata": {
        "id": "2OPM94lHkuG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Tb7gGdMetZX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69a188a-8527-4fa7-8830-2d673ab27d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved documents: ['crisis vestibuloocular ref ex scan aureus ventricular septal defect ventricular tachycardia von willebrands disease von willebrand factor varicellazoster virus white blood cell world health organization hemoglobin plasma mean corpuscular hemoglobin platelet count prothrombin time reticulocyte count sedimentation rate erythrocyte westergren proteins total mgdl moll mm pgcell fmolcell mm seconds seconds of red cells male mmh mmh female mmh mmh mg', 'crisis vestibuloocular ref ex scan aureus ventricular septal defect ventricular tachycardia von willebrands disease von willebrand factor varicellazoster virus white blood cell world health organization hemoglobin plasma mean corpuscular hemoglobin platelet count prothrombin time reticulocyte count sedimentation rate erythrocyte westergren proteins total mgdl moll mm pgcell fmolcell mm seconds seconds of red cells male mmh mmh female mmh mmh mg', 'crisis vestibuloocular ref ex scan aureus ventricular septal defect ventricular tachycardia von willebrands disease von willebrand factor varicellazoster virus white blood cell world health organization hemoglobin plasma mean corpuscular hemoglobin platelet count prothrombin time reticulocyte count sedimentation rate erythrocyte westergren proteins total mgdl moll mm pgcell fmolcell mm seconds seconds of red cells male mmh mmh female mmh mmh mg', 'crisis vestibuloocular ref ex scan aureus ventricular septal defect ventricular tachycardia von willebrands disease von willebrand factor varicellazoster virus white blood cell world health organization hemoglobin plasma mean corpuscular hemoglobin platelet count prothrombin time reticulocyte count sedimentation rate erythrocyte westergren proteins total mgdl moll mm pgcell fmolcell mm seconds seconds of red cells male mmh mmh female mmh mmh mg', 'crisis vestibuloocular ref ex scan aureus ventricular septal defect ventricular tachycardia von willebrands disease von willebrand factor varicellazoster virus white blood cell world health organization hemoglobin plasma mean corpuscular hemoglobin platelet count prothrombin time reticulocyte count sedimentation rate erythrocyte westergren proteins total mgdl moll mm pgcell fmolcell mm seconds seconds of red cells male mmh mmh female mmh mmh mg']\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model for retrieval on CPU\n",
        "retrieval_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "retrieval_model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").cpu()\n",
        "\n",
        "# Function to generate embeddings for a new query\n",
        "def get_query_embedding(query):\n",
        "    with torch.no_grad():\n",
        "        inputs = retrieval_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        outputs = retrieval_model(**inputs)\n",
        "        embedding = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "    return embedding\n",
        "\n",
        "# Load FAISS index with existing embeddings\n",
        "embedding_dim = 384\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "# Function to retrieve relevant documents based on the query\n",
        "def retrieve_documents(query, top_k=5):\n",
        "    query_embedding = get_query_embedding(query).astype(\"float32\")\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    results = [chunked_documents[idx] for idx in indices[0]]\n",
        "    return results\n",
        "\n",
        "# Test retrieval component\n",
        "sample_query = \"What are the symptoms of heart failure?\"\n",
        "similar_documents = retrieve_documents(sample_query)\n",
        "print(\"Retrieved documents:\", similar_documents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation Method"
      ],
      "metadata": {
        "id": "ylpKt7T1r8zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generation_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", trust_remote_code=True)\n",
        "generation_model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\", trust_remote_code=True)\n",
        "generation_model.to(device)\n"
      ],
      "metadata": {
        "id": "YeBUoKYNxQ51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "a4e062aa22d34ce088e190cce4112d8f",
            "dc24e588ddf14db7bfc9f1a4b61cb46e",
            "1b1f566b59b94c0c93a8d64c1e3d8dbd",
            "5f4ca6ff3ba446858603d0a67c9d8544",
            "c5dd89fc729b4523bde3af16512d333c",
            "29a7ca8f41054655b337c15122095213",
            "1d521beeda024a26bb17ba4adf3bfc3c",
            "863f3a0276054051b3017a9efb3b2b44",
            "50883636da964a7c866b80f0347b1d21",
            "7dc13ba6292f4a9f9e4acfa895a8c96b",
            "f559699a0c8f46a4b65f00b53c7e9c4e"
          ]
        },
        "outputId": "74768e04-3a88-4089-d450-cd4f48dd2667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.3145e03a9fd4cdd7cd953c34d9bbf7ad606122ca.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e062aa22d34ce088e190cce4112d8f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to generate a response using retrieved context\n",
        "def generate_response(query, context, max_new_tokens=100):\n",
        "    input_text = f\"User query: {query}\\n\\nContext:\\n{context}\\n\\nAnswer:\"\n",
        "\n",
        "    # Tokenize the input and move tensors to GPU\n",
        "    inputs = generation_tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "    # Generate response using max_new_tokens to control output length\n",
        "    with torch.no_grad():\n",
        "        outputs = generation_model.generate(inputs[\"input_ids\"], max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
        "\n",
        "    # Decode the generated response\n",
        "    response_text = generation_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response_text\n",
        "\n",
        "# Testing generation with retrieved documents as context\n",
        "retrieved_text = \" \".join(similar_documents)  # Concatenate retrieved documents as context\n",
        "response = generate_response(sample_query, retrieved_text)\n",
        "print(\"Generated response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6abG8NMVr6hi",
        "outputId": "b76b7ada-eb07-4ff9-9f94-950977ff511d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated response: User query: What are the symptoms of heart failure?\n",
            "\n",
            "Context:\n",
            "artery pip bisphosphate pip bisphosphate po partial pressure of oxygen pv plasma volume venous pressure correlation coefficient right variable group registration ranking results system rankl receptor activator of nuclear factor ligand rr relative risk respiratory rate rv residual volume right ventricle right ventricular se standard error of the mean siadh syndrome of inappropriate secretion of antidiuretic hormone sv splenic vein stroke volume tca tricarboxylic acid cycle tricyclic antidepressant vasopressin receptors vd volume of distribution vdj variable diversity joining gene segments rearranged to form ig genes vh variable region heavy chain antibody vl variable region light chain antibody vpl ventral posterior nucleus lateral vpm ventral posterior nucleus medial vpn vancomycin polymyxin nystatin media ratio xr xlinked recessive xxxy normal complement of sex chromosomes for femalemale zdv zidovudine formerly azt artery pip bisphosphate pip bisphosphate po partial pressure of oxygen pv plasma volume venous pressure correlation coefficient right variable group registration ranking results system rankl receptor activator of nuclear factor ligand rr relative risk respiratory rate rv residual volume right ventricle right ventricular se standard error of the mean siadh syndrome of inappropriate secretion of antidiuretic hormone sv splenic vein stroke volume tca tricarboxylic acid cycle tricyclic antidepressant vasopressin receptors vd volume of distribution vdj variable diversity joining gene segments rearranged to form ig genes vh variable region heavy chain antibody vl variable region light chain antibody vpl ventral posterior nucleus lateral vpm ventral posterior nucleus medial vpn vancomycin polymyxin nystatin media ratio xr xlinked recessive xxxy normal complement of sex chromosomes for femalemale zdv zidovudine formerly azt artery pip bisphosphate pip bisphosphate po partial pressure of oxygen pv plasma volume venous pressure correlation coefficient right variable group registration ranking results system rankl receptor activator of nuclear factor ligand rr relative risk respiratory rate rv residual volume right ventricle right ventricular se standard error of the mean siadh syndrome of inappropriate secretion of antidiuretic hormone sv splenic vein stroke volume tca tricarboxylic acid cycle tricyclic antidepressant vasopressin receptors vd volume of distribution vdj variable diversity joining gene segments rearranged to form ig genes vh variable region heavy chain antibody vl variable region light chain antibody vpl ventral posterior nucleus lateral vpm ventral posterior nucleus medial vpn vancomycin polymyxin nystatin media ratio xr xlinked recessive xxxy normal complement of sex chromosomes for femalemale zdv zidovudine formerly azt artery pip bisphosphate pip bisphosphate po partial pressure of oxygen pv plasma volume venous pressure correlation coefficient right variable group registration ranking results system rankl receptor activator of nuclear factor ligand rr relative risk respiratory rate rv residual volume right ventricle right ventricular se standard error of the mean siadh syndrome of inappropriate secretion of antidiuretic hormone sv splenic vein stroke volume tca tricarboxylic acid cycle tricyclic antidepressant vasopressin receptors vd volume of distribution vdj variable diversity joining gene segments rearranged to form ig genes vh variable region heavy chain antibody vl variable region light chain antibody vpl ventral posterior nucleus lateral vpm ventral posterior nucleus medial vpn vancomycin polymyxin nystatin media ratio xr xlinked recessive xxxy normal complement of sex chromosomes for femalemale zdv zidovudine formerly azt artery pip bisphosphate pip bisphosphate po partial pressure of oxygen pv plasma volume venous pressure correlation coefficient right variable group registration ranking results system rankl receptor activator of nuclear factor ligand rr relative risk respiratory rate rv residual volume right ventricle right ventricular se standard error of the mean siadh syndrome of inappropriate secretion of antidiuretic hormone sv splenic vein stroke volume tca tricarboxylic acid cycle tricyclic antidepressant vasopressin receptors vd volume of distribution vdj variable diversity joining gene segments rearranged to form ig genes vh variable region heavy chain antibody vl variable region light chain antibody vpl ventral posterior nucleus lateral vpm ventral posterior nucleus medial vpn vancomycin polymyxin nystatin media ratio xr xlinked recessive xxxy normal complement of sex chromosomes for femalemale zdv zidovudine formerly azt\n",
            "\n",
            "Answer: The symptoms of heart failure can vary depending on the severity and the underlying cause, but common signs and symptoms include:\n",
            "\n",
            "1. Shortness of breath or difficulty breathing (dyspnea), especially during physical activity or when lying down\n",
            "2. Fatigue and weakness\n",
            "3. Swelling (edema) in the legs, ankles, feet, or abdomen due to fluid retention\n",
            "4. Rapid or irregular heartbeat\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2LBrTCo_mX6N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4e062aa22d34ce088e190cce4112d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc24e588ddf14db7bfc9f1a4b61cb46e",
              "IPY_MODEL_1b1f566b59b94c0c93a8d64c1e3d8dbd",
              "IPY_MODEL_5f4ca6ff3ba446858603d0a67c9d8544"
            ],
            "layout": "IPY_MODEL_c5dd89fc729b4523bde3af16512d333c"
          }
        },
        "dc24e588ddf14db7bfc9f1a4b61cb46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a7ca8f41054655b337c15122095213",
            "placeholder": "​",
            "style": "IPY_MODEL_1d521beeda024a26bb17ba4adf3bfc3c",
            "value": "Loading checkpoint shards:  50%"
          }
        },
        "1b1f566b59b94c0c93a8d64c1e3d8dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863f3a0276054051b3017a9efb3b2b44",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50883636da964a7c866b80f0347b1d21",
            "value": 1
          }
        },
        "5f4ca6ff3ba446858603d0a67c9d8544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc13ba6292f4a9f9e4acfa895a8c96b",
            "placeholder": "​",
            "style": "IPY_MODEL_f559699a0c8f46a4b65f00b53c7e9c4e",
            "value": " 1/2 [03:01&lt;03:01, 181.39s/it]"
          }
        },
        "c5dd89fc729b4523bde3af16512d333c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a7ca8f41054655b337c15122095213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d521beeda024a26bb17ba4adf3bfc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "863f3a0276054051b3017a9efb3b2b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50883636da964a7c866b80f0347b1d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dc13ba6292f4a9f9e4acfa895a8c96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f559699a0c8f46a4b65f00b53c7e9c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}